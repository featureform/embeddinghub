name: HDFS Testing
on:
  pull_request:
    branches: '**'
  push:
    branches: 'release/**'

concurrency:
  group: ${{ github.head_ref }}-e2e
  cancel-in-progress: true
jobs:

  test:
    name: Run Tests
    defaults:
      run:
        working-directory: ./
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-python@v4
        with:
          python-version: "3.7"
          check-latest: true


      - name: Install Python Dependencies
        run: |
          pip install pyyaml click
          pip install -r ./backup/requirements.txt

      - name: Build and Run HDFS
        env:
          HDFSCLI_CONFIG: ./tests/end_to_end/hdfs/hdfscli.cfg
        run: |
          pip install hdfs
          git clone https://github.com/rancavil/hadoop-single-node-cluster.git
          cd hadoop-single-node-cluster
          docker build -t hadoop .
          docker run -d --name hadoop -p 9864:9864 -p 9870:9870 -p 8088:8088 -p 9000:9000 -p 9866:9866 --hostname localhost hadoop
          cd ..
          until hdfscli upload --alias=dev ./tests/end_to_end/hdfs/ice_cream.parquet /ice_cream.parquet; do echo “Waiting For HDFS To Be Ready”; sleep 1; done; echo "Done"

      - name: Cleanup Hadoop
        if: always()
        continue-on-error: true
        run: docker rm hadoop